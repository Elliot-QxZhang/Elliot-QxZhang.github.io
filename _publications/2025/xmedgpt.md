---
title:          "Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration"
date:           2025-5-1 00:01:00 +0800
selected:       true
pub:            "Under Review"
pub_last:       ' <span class="badge badge-pill badge-success badge-publication">Segmentation</span>'
pub_date:       "2025"
abstract: >-
 Generalist Medical AI (GMAI) systems have demonstrated expert-level performance in biomedical perception tasks, yet their clinical utility remains limited by inadequate multi-modal explainability and suboptimal prognostic capabilities. Here, we present XMedGPT, a clinician-centric, multi-modal AI assistant that integrates textual and visual interpretability to support transparent and trustworthy medical decision-making. XMedGPT not only produces accurate diagnostic and descriptive outputs, but also grounds referenced anatomical sites within medical images, bridging critical gaps in interpretability and enhancing clinician usability.
cover: /assets/images/covers/xmedgpt.png
authors:
  - Honglong Yang
  - Shanshan Song
  - Yi Qin
  - Lehan Wang
  - Haonan Wang
  - Xinpeng Ding
  - <b>Qixiang Zhang</b>
  - Bodong Du
  - Xiaomeng Li
links:
  Preprint: https://arxiv.org/abs/2505.03380
  Code: None
---

